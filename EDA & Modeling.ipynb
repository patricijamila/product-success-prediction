{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from matplotlib import pyplot\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training and test datasets\n",
    "\n",
    "parq_file = 'data.parquet'\n",
    "data = pd.read_parquet(parq_file, 'auto')\n",
    "\n",
    "parq_file_test = 'test.parquet'\n",
    "data_test = pd.read_parquet(parq_file_test, 'auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training dataset has 666814 rows and 76 columns\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test dataset has 74091 rows and 74 columns, 2 columns less\n",
    "\n",
    "data_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns not present in the test set will be removed before training the model:\n",
    "# listing_price_local, sale_time\n",
    "\n",
    "for i in data.columns:\n",
    "    if i not in data_test.columns:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check column names, data types, non-null counts\n",
    "\n",
    "data.info()\n",
    "data_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check format of sale_time and local_time to calculate the difference\n",
    "\n",
    "data['sale_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['local_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace all None values in sale_time with a placeholder\n",
    "\n",
    "data[\"sale_time\"].replace({None: \"2025-01-01T00:00:00.000-07:00\"}, inplace=True)\n",
    "data[\"sale_time\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace all missing values with 'na' which will be encoded\n",
    "\n",
    "data = data.fillna('na')\n",
    "\n",
    "# Create a no_hashtags column containing a number of hashtags for that listing \n",
    "# which will be used as a variable instead of the hashtags column (easier to measure)\n",
    "\n",
    "def no_hashtags(hashtags):\n",
    "    no_hashtags = int(hashtags.size)\n",
    "    return no_hashtags\n",
    "\n",
    "data['no_hashtags'] = data.apply(lambda row: no_hashtags(row['hashtags']), axis=1)\n",
    "\n",
    "# Add a column that contains the time in which the product was sold\n",
    "# We only care about whether something was sold in 24 hours or not, so the placeholder dates\n",
    "# will be a lot larger than that\n",
    "\n",
    "def conversion(sale, local):\n",
    "    frmt = \"%Y-%m-%dT%H:%M:%S.%f%z\"\n",
    "    sold_in = datetime.strptime(sale, frmt) - datetime.strptime(local, frmt)\n",
    "    return sold_in\n",
    "\n",
    "data['sold_in'] = data.apply(lambda row: conversion(row['sale_time'], row['local_time']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        2284 days 04:53:39\n",
       "1        2368 days 08:57:28\n",
       "2        2300 days 03:23:21\n",
       "3        2168 days 00:54:19\n",
       "4        2108 days 12:03:50\n",
       "                ...        \n",
       "666809   2117 days 15:37:58\n",
       "666810   2275 days 10:02:05\n",
       "666811   2145 days 03:47:50\n",
       "666812      6 days 04:42:57\n",
       "666813   2370 days 06:41:30\n",
       "Name: sold_in, Length: 666814, dtype: timedelta64[ns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if the new column generated correctly\n",
    "\n",
    "data['sold_in']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>local_time</th>\n",
       "      <th>sale_time</th>\n",
       "      <th>sold_in</th>\n",
       "      <th>sold_in_24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2018-09-19T03:36:55.000-07:00</td>\n",
       "      <td>2018-09-19T04:15:43.000-07:00</td>\n",
       "      <td>00:38:48</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>2019-04-22T16:23:24.000-07:00</td>\n",
       "      <td>2019-04-22T18:02:30.000-07:00</td>\n",
       "      <td>01:39:06</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>2019-03-17T18:44:38.000-07:00</td>\n",
       "      <td>2019-03-18T15:44:10.000-07:00</td>\n",
       "      <td>20:59:32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>2019-01-22T19:57:58.000-07:00</td>\n",
       "      <td>2019-01-23T08:45:58.000-07:00</td>\n",
       "      <td>12:48:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>2018-08-17T19:00:16.000-07:00</td>\n",
       "      <td>2018-08-17T21:58:46.000-07:00</td>\n",
       "      <td>02:58:30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>2019-02-17T15:22:28.000-07:00</td>\n",
       "      <td>2019-02-17T17:42:59.000-07:00</td>\n",
       "      <td>02:20:31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>2018-09-15T20:31:26.000-07:00</td>\n",
       "      <td>2018-09-15T23:26:25.000-07:00</td>\n",
       "      <td>02:54:59</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>2019-03-22T20:46:35.000-07:00</td>\n",
       "      <td>2019-03-22T20:55:01.000-07:00</td>\n",
       "      <td>00:08:26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>2018-07-05T21:01:38.000-07:00</td>\n",
       "      <td>2018-07-05T21:03:32.000-07:00</td>\n",
       "      <td>00:01:54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>2019-02-27T17:40:49.000-07:00</td>\n",
       "      <td>2019-02-27T20:41:10.000-07:00</td>\n",
       "      <td>03:00:21</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        local_time                      sale_time  sold_in  \\\n",
       "29   2018-09-19T03:36:55.000-07:00  2018-09-19T04:15:43.000-07:00 00:38:48   \n",
       "216  2019-04-22T16:23:24.000-07:00  2019-04-22T18:02:30.000-07:00 01:39:06   \n",
       "217  2019-03-17T18:44:38.000-07:00  2019-03-18T15:44:10.000-07:00 20:59:32   \n",
       "274  2019-01-22T19:57:58.000-07:00  2019-01-23T08:45:58.000-07:00 12:48:00   \n",
       "277  2018-08-17T19:00:16.000-07:00  2018-08-17T21:58:46.000-07:00 02:58:30   \n",
       "294  2019-02-17T15:22:28.000-07:00  2019-02-17T17:42:59.000-07:00 02:20:31   \n",
       "369  2018-09-15T20:31:26.000-07:00  2018-09-15T23:26:25.000-07:00 02:54:59   \n",
       "383  2019-03-22T20:46:35.000-07:00  2019-03-22T20:55:01.000-07:00 00:08:26   \n",
       "515  2018-07-05T21:01:38.000-07:00  2018-07-05T21:03:32.000-07:00 00:01:54   \n",
       "527  2019-02-27T17:40:49.000-07:00  2019-02-27T20:41:10.000-07:00 03:00:21   \n",
       "\n",
       "     sold_in_24  \n",
       "29            1  \n",
       "216           1  \n",
       "217           1  \n",
       "274           1  \n",
       "277           1  \n",
       "294           1  \n",
       "369           1  \n",
       "383           1  \n",
       "515           1  \n",
       "527           1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a column separating listings sold in 24 hours (1) and ones that weren't (0)\n",
    "# This will be the dependent variable\n",
    "\n",
    "def separation(sold_in):\n",
    "    if sold_in <= timedelta(days = 1):\n",
    "        sold_in_24 = 1\n",
    "    elif sold_in > timedelta(days = 1):\n",
    "        sold_in_24 = 0\n",
    "    return sold_in_24\n",
    "\n",
    "data['sold_in_24'] = data.apply(lambda row: separation(row['sold_in']), axis=1)\n",
    "\n",
    "# Check if the calculations were correct\n",
    "\n",
    "data2 = data[data['sold_in_24'] == 1]\n",
    "data3 = data2.filter(['local_time', 'sale_time', 'sold_in','sold_in_24'])\n",
    "data3[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See all columns and what their values are to determine which columns should already be dropped\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 666814 entries, 0 to 666813\n",
      "Data columns (total 41 columns):\n",
      " #   Column                         Non-Null Count   Dtype  \n",
      "---  ------                         --------------   -----  \n",
      " 0   brand                          666814 non-null  object \n",
      " 1   catalog_code_1                 666814 non-null  object \n",
      " 2   catalog_code_2                 666814 non-null  object \n",
      " 3   catalog_code_3                 666814 non-null  object \n",
      " 4   catalog_code_4                 666814 non-null  object \n",
      " 5   catalog_code_5                 666814 non-null  object \n",
      " 6   color_primary                  666814 non-null  object \n",
      " 7   color_secondary                666814 non-null  object \n",
      " 8   disposal_conditions_string     666814 non-null  object \n",
      " 9   listing_platform               666814 non-null  object \n",
      " 10  package_size_code              666814 non-null  object \n",
      " 11  size                           666814 non-null  object \n",
      " 12  with_video                     666814 non-null  int64  \n",
      " 13  birthday                       666814 non-null  object \n",
      " 14  city                           666814 non-null  object \n",
      " 15  country_code                   666814 non-null  object \n",
      " 16  gender                         666814 non-null  object \n",
      " 17  language                       666814 non-null  object \n",
      " 18  state                          666814 non-null  object \n",
      " 19  lister_nth_day_of_listing      666814 non-null  int32  \n",
      " 20  lister_nth_listing             666814 non-null  int32  \n",
      " 21  listing_activity               666814 non-null  object \n",
      " 22  total_feedback_count           666814 non-null  int64  \n",
      " 23  total_gmv_bought               666814 non-null  float64\n",
      " 24  total_gmv_sold                 666814 non-null  float64\n",
      " 25  total_items_bought             666814 non-null  int64  \n",
      " 26  total_items_listed             666814 non-null  int64  \n",
      " 27  total_items_sold               666814 non-null  int64  \n",
      " 28  total_negative_feedback_count  666814 non-null  int64  \n",
      " 29  total_neutral_feedback_count   666814 non-null  int64  \n",
      " 30  total_positive_feedback_count  666814 non-null  int64  \n",
      " 31  window_gmv_bought              666814 non-null  float64\n",
      " 32  window_gmv_sold                666814 non-null  float64\n",
      " 33  window_items_bought            666814 non-null  int64  \n",
      " 34  window_items_listed            666814 non-null  int64  \n",
      " 35  window_items_sold              666814 non-null  int64  \n",
      " 36  acquisition_type               666814 non-null  object \n",
      " 37  got_voucher                    666814 non-null  object \n",
      " 38  paid_organic                   666814 non-null  object \n",
      " 39  no_hashtags                    666814 non-null  int64  \n",
      " 40  sold_in_24                     666814 non-null  int64  \n",
      "dtypes: float64(4), int32(2), int64(13), object(22)\n",
      "memory usage: 203.5+ MB\n"
     ]
    }
   ],
   "source": [
    "# Drop columns that should not contribute to success of a listing, to ease the training process\n",
    "# Listing_price_local is removed because test set doesn't have this column\n",
    "\n",
    "data = data.drop(['title','listing_price_local', 'portal','sold_in', 'brand_is_verified', 'hashtags', 'local_time', 'sale_time'], axis = 1)\n",
    "data = data.drop(data.loc[:,'custom_shipping_price_domestic':'disposal_conditions'].columns, axis = 1)\n",
    "data = data.drop(data.loc[:, 'basic_verification_local_time':'lifetime'].columns, axis = 1)\n",
    "data = data.drop(data.loc[:, 'phone_verification_local_time':'second_sale_local_time'].columns, axis = 1)\n",
    "data = data.drop(data.loc[:, 'registration_app_id':'registration_type'].columns, axis = 1)\n",
    "\n",
    "# Change the boolean \"True\" or \"False\" column into 1 and 0\n",
    "        \n",
    "data['with_video'] = data['with_video']*1\n",
    "\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn object data type columns into categories and then encode each category \n",
    "# so all variables are numeric\n",
    "\n",
    "for col_name in data.columns:\n",
    "    if(data[col_name].dtype == 'object'):\n",
    "        data[col_name]= data[col_name].astype('category')\n",
    "        data[col_name] = data[col_name].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 666814 entries, 0 to 666813\n",
      "Data columns (total 41 columns):\n",
      " #   Column                         Non-Null Count   Dtype  \n",
      "---  ------                         --------------   -----  \n",
      " 0   brand                          666814 non-null  int16  \n",
      " 1   catalog_code_1                 666814 non-null  int8   \n",
      " 2   catalog_code_2                 666814 non-null  int8   \n",
      " 3   catalog_code_3                 666814 non-null  int16  \n",
      " 4   catalog_code_4                 666814 non-null  int16  \n",
      " 5   catalog_code_5                 666814 non-null  int8   \n",
      " 6   color_primary                  666814 non-null  int8   \n",
      " 7   color_secondary                666814 non-null  int8   \n",
      " 8   disposal_conditions_string     666814 non-null  int8   \n",
      " 9   listing_platform               666814 non-null  int8   \n",
      " 10  package_size_code              666814 non-null  int8   \n",
      " 11  size                           666814 non-null  int16  \n",
      " 12  with_video                     666814 non-null  int64  \n",
      " 13  birthday                       666814 non-null  int16  \n",
      " 14  city                           666814 non-null  int16  \n",
      " 15  country_code                   666814 non-null  int8   \n",
      " 16  gender                         666814 non-null  int8   \n",
      " 17  language                       666814 non-null  int8   \n",
      " 18  state                          666814 non-null  int8   \n",
      " 19  lister_nth_day_of_listing      666814 non-null  int32  \n",
      " 20  lister_nth_listing             666814 non-null  int32  \n",
      " 21  listing_activity               666814 non-null  int8   \n",
      " 22  total_feedback_count           666814 non-null  int64  \n",
      " 23  total_gmv_bought               666814 non-null  float64\n",
      " 24  total_gmv_sold                 666814 non-null  float64\n",
      " 25  total_items_bought             666814 non-null  int64  \n",
      " 26  total_items_listed             666814 non-null  int64  \n",
      " 27  total_items_sold               666814 non-null  int64  \n",
      " 28  total_negative_feedback_count  666814 non-null  int64  \n",
      " 29  total_neutral_feedback_count   666814 non-null  int64  \n",
      " 30  total_positive_feedback_count  666814 non-null  int64  \n",
      " 31  window_gmv_bought              666814 non-null  float64\n",
      " 32  window_gmv_sold                666814 non-null  float64\n",
      " 33  window_items_bought            666814 non-null  int64  \n",
      " 34  window_items_listed            666814 non-null  int64  \n",
      " 35  window_items_sold              666814 non-null  int64  \n",
      " 36  acquisition_type               666814 non-null  int8   \n",
      " 37  got_voucher                    666814 non-null  int8   \n",
      " 38  paid_organic                   666814 non-null  int8   \n",
      " 39  no_hashtags                    666814 non-null  int64  \n",
      " 40  sold_in_24                     666814 non-null  int64  \n",
      "dtypes: float64(4), int16(6), int32(2), int64(13), int8(16)\n",
      "memory usage: 109.4 MB\n"
     ]
    }
   ],
   "source": [
    "# Check how the dataset looks now\n",
    "# Only float and integer columns left which the model will be able to handle\n",
    "\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign independent (X) and dependent (y) variables\n",
    "\n",
    "y = data.pop('sold_in_24')\n",
    "X = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training, test and validation sets\n",
    "\n",
    "seed = 50\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state = seed)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train,y_train, test_size=0.2, random_state = seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='entropy', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "                       n_jobs=None, oob_score=False, random_state=50, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create and fit Random Forest model\n",
    "\n",
    "model = RandomForestClassifier(n_estimators = 200, criterion = 'entropy', random_state = seed)\n",
    "\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the validation set\n",
    "\n",
    "y_pred = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[103662,    269],\n",
       "       [  2417,    343]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model evaluation / Confusion Matrix\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_m_val = confusion_matrix(y_val, y_pred)\n",
    "confusion_m_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9748244931624973\n",
      "precision: 0.5604575163398693\n",
      "recall: 0.12427536231884058\n",
      "f1: 0.20344009489916962\n"
     ]
    }
   ],
   "source": [
    "# Accuracy, Precision, Recall and F1 scores\n",
    "\n",
    "\n",
    "accuracy_val = accuracy_score(y_val, y_pred)\n",
    "print(\"accuracy:\", accuracy_val)\n",
    "\n",
    "precision_val = precision_score(y_val, y_pred)\n",
    "print(\"precision:\", precision_val)\n",
    "\n",
    "recall_val = recall_score(y_val, y_pred)\n",
    "print(\"recall:\", recall_val)\n",
    "\n",
    "f1_val = f1_score(y_val, y_pred)\n",
    "print(\"f1:\", f1_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save this model\n",
    "\n",
    "pickle.dump(model, open('baseline_model.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: 0, Score: 0.05189\n",
      "Feature: 1, Score: 0.00264\n",
      "Feature: 2, Score: 0.01109\n",
      "Feature: 3, Score: 0.03475\n",
      "Feature: 4, Score: 0.04616\n",
      "Feature: 5, Score: 0.00344\n",
      "Feature: 6, Score: 0.04094\n",
      "Feature: 7, Score: 0.03116\n",
      "Feature: 8, Score: 0.00281\n",
      "Feature: 9, Score: 0.00657\n",
      "Feature: 10, Score: 0.00790\n",
      "Feature: 11, Score: 0.03745\n",
      "Feature: 12, Score: 0.00035\n",
      "Feature: 13, Score: 0.04571\n",
      "Feature: 14, Score: 0.03739\n",
      "Feature: 15, Score: 0.00000\n",
      "Feature: 16, Score: 0.00125\n",
      "Feature: 17, Score: 0.00147\n",
      "Feature: 18, Score: 0.02779\n",
      "Feature: 19, Score: 0.05195\n",
      "Feature: 20, Score: 0.07541\n",
      "Feature: 21, Score: 0.00701\n",
      "Feature: 22, Score: 0.03240\n",
      "Feature: 23, Score: 0.02389\n",
      "Feature: 24, Score: 0.04870\n",
      "Feature: 25, Score: 0.02033\n",
      "Feature: 26, Score: 0.04929\n",
      "Feature: 27, Score: 0.04257\n",
      "Feature: 28, Score: 0.01169\n",
      "Feature: 29, Score: 0.00561\n",
      "Feature: 30, Score: 0.03212\n",
      "Feature: 31, Score: 0.01499\n",
      "Feature: 32, Score: 0.06353\n",
      "Feature: 33, Score: 0.01108\n",
      "Feature: 34, Score: 0.04849\n",
      "Feature: 35, Score: 0.04966\n",
      "Feature: 36, Score: 0.00469\n",
      "Feature: 37, Score: 0.00333\n",
      "Feature: 38, Score: 0.00230\n",
      "Feature: 39, Score: 0.01018\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Find scores that show how important each feature is\n",
    "\n",
    "importance = model.feature_importances_\n",
    "\n",
    "importances_dict = {}\n",
    "\n",
    "for i,v in enumerate(importance):\n",
    "    print('Feature: %0d, Score: %.5f' % (i,v))\n",
    "    importances_dict[i] = v\n",
    "\n",
    "# plot feature importance\n",
    "pyplot.bar([x for x in range(len(importance))], importance)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n"
     ]
    }
   ],
   "source": [
    "# Find how many are above >= 0.01\n",
    "\n",
    "top = []\n",
    "\n",
    "for i in importance:\n",
    "    if i >= 0.01:\n",
    "        top.append(i)\n",
    "\n",
    "amount_top_features = len(top)\n",
    "print(amount_top_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lister_nth_listing',\n",
       " 'window_gmv_sold',\n",
       " 'lister_nth_day_of_listing',\n",
       " 'brand',\n",
       " 'window_items_sold',\n",
       " 'total_items_listed',\n",
       " 'total_gmv_sold',\n",
       " 'window_items_listed',\n",
       " 'catalog_code_4',\n",
       " 'birthday',\n",
       " 'total_items_sold',\n",
       " 'color_primary',\n",
       " 'size',\n",
       " 'city',\n",
       " 'catalog_code_3',\n",
       " 'total_feedback_count',\n",
       " 'total_positive_feedback_count',\n",
       " 'color_secondary',\n",
       " 'state',\n",
       " 'total_gmv_bought',\n",
       " 'total_items_bought',\n",
       " 'window_gmv_bought',\n",
       " 'total_negative_feedback_count',\n",
       " 'catalog_code_2',\n",
       " 'window_items_bought',\n",
       " 'no_hashtags']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort features and extract top (scores >=  0.01)\n",
    "\n",
    "sorted_features = sorted(importances_dict.items(), key = lambda x: x[1], reverse = True)\n",
    "\n",
    "sorted_features_top = sorted_features[0:26]\n",
    "\n",
    "top_features = []\n",
    "\n",
    "for i in sorted_features_top:\n",
    "    top_features.append(i[0])\n",
    "\n",
    "# Find feature names\n",
    "\n",
    "column_numbers = {}\n",
    "\n",
    "for i,v in enumerate(data.columns):\n",
    "    column_numbers[i] = v\n",
    "\n",
    "# Match feature names and numbers\n",
    "    \n",
    "top_features_numbered = {}\n",
    "\n",
    "for i in top_features:\n",
    "    top_features_numbered[i] = column_numbers.get(i)\n",
    "    \n",
    "\n",
    "# Extract top feature names\n",
    "    \n",
    "top_important_features = []\n",
    "\n",
    "for i in top_features_numbered.values():\n",
    "    top_important_features.append(i)\n",
    "    \n",
    "top_important_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only important features for a new training/test set\n",
    "\n",
    "X_train = X_train[top_important_features]\n",
    "X_test = X_test[top_important_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='entropy', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "                       n_jobs=None, oob_score=False, random_state=50, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrain the model using important features\n",
    "\n",
    "model = RandomForestClassifier(n_estimators = 200, criterion = 'entropy', random_state = seed)\n",
    "\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "\n",
    "y_pred_test = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[129547,    311],\n",
       "       [  3095,    410]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model evaluation / Confusion Matrix\n",
    "\n",
    "confusion_m_test = confusion_matrix(y_test, y_pred_test)\n",
    "confusion_m_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.9748244931624973\n",
      "Test accuracy: 0.9744606824981442\n",
      "Validation precision: 0.5604575163398693\n",
      "Test precision: 0.5686546463245492\n",
      "Validation recall: 0.12427536231884058\n",
      "Test recall: 0.11697574893009986\n",
      "Validation f1: 0.20344009489916962\n",
      "Test f1: 0.19403691433980122\n"
     ]
    }
   ],
   "source": [
    "# Model evaluation and comparison / Accuracy, Precision, Recall, F1\n",
    "\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "print(\"Validation accuracy:\", accuracy_val)\n",
    "print(\"Test accuracy:\", accuracy_test)\n",
    "\n",
    "precision_test = precision_score(y_test, y_pred_test)\n",
    "print(\"Validation precision:\", precision_val)\n",
    "print(\"Test precision:\", precision_test)\n",
    "\n",
    "recall_test = recall_score(y_test, y_pred_test)\n",
    "print(\"Validation recall:\", recall_val)\n",
    "print(\"Test recall:\", recall_test)\n",
    "\n",
    "f1_test = f1_score(y_test, y_pred_test)\n",
    "print(\"Validation f1:\", f1_val)\n",
    "print(\"Test f1:\", f1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save this model\n",
    "\n",
    "pickle.dump(model, open('top_features_model.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare final test data\n",
    "\n",
    "# Replace all missing values with 'na' which will be encoded\n",
    "\n",
    "data_test = data_test.fillna('na')\n",
    "\n",
    "# Create a no_hashtags column containing a number of hashtags for that listing \n",
    "# which will be used as a variable instead of the hashtags column (easier to measure)\n",
    "\n",
    "def no_hashtags(hashtags):\n",
    "    no_hashtags = int(hashtags.size)\n",
    "    return no_hashtags\n",
    "\n",
    "data_test['no_hashtags'] = data_test.apply(lambda row: no_hashtags(row['hashtags']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only the top important features for the test set\n",
    "\n",
    "X_test_final = data_test[top_important_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Encode all object variables\n",
    "\n",
    "for col_name in X_test_final.columns:\n",
    "    if(X_test_final[col_name].dtype == 'object'):\n",
    "        X_test_final[col_name]= X_test_final[col_name].astype('category')\n",
    "        X_test_final[col_name] = X_test_final[col_name].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 74091 entries, 0 to 74090\n",
      "Data columns (total 26 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   lister_nth_listing             74091 non-null  int32  \n",
      " 1   window_gmv_sold                74091 non-null  float64\n",
      " 2   lister_nth_day_of_listing      74091 non-null  int32  \n",
      " 3   brand                          74091 non-null  int16  \n",
      " 4   window_items_sold              74091 non-null  int64  \n",
      " 5   total_items_listed             74091 non-null  int64  \n",
      " 6   total_gmv_sold                 74091 non-null  float64\n",
      " 7   window_items_listed            74091 non-null  int64  \n",
      " 8   catalog_code_4                 74091 non-null  int16  \n",
      " 9   birthday                       74091 non-null  int16  \n",
      " 10  total_items_sold               74091 non-null  int64  \n",
      " 11  color_primary                  74091 non-null  int8   \n",
      " 12  size                           74091 non-null  int16  \n",
      " 13  city                           74091 non-null  int16  \n",
      " 14  catalog_code_3                 74091 non-null  int16  \n",
      " 15  total_feedback_count           74091 non-null  int64  \n",
      " 16  total_positive_feedback_count  74091 non-null  int64  \n",
      " 17  color_secondary                74091 non-null  int8   \n",
      " 18  state                          74091 non-null  int8   \n",
      " 19  total_gmv_bought               74091 non-null  float64\n",
      " 20  total_items_bought             74091 non-null  int64  \n",
      " 21  window_gmv_bought              74091 non-null  float64\n",
      " 22  total_negative_feedback_count  74091 non-null  int64  \n",
      " 23  catalog_code_2                 74091 non-null  int8   \n",
      " 24  window_items_bought            74091 non-null  int64  \n",
      " 25  no_hashtags                    74091 non-null  int64  \n",
      "dtypes: float64(4), int16(6), int32(2), int64(10), int8(4)\n",
      "memory usage: 9.6 MB\n"
     ]
    }
   ],
   "source": [
    "X_test_final.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pickle.load(open('top_features_model.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "\n",
    "y_pred_final = model.predict(X_test_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# Add a predictions column to the test data then filter the rows that were predicted to be sold within 24 hours\n",
    "\n",
    "X_test_final['predicted_label'] = y_pred_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_final = X_test_final[X_test_final['predicted_label'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51, 27)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 51 lines of the test dataset were predicted to be sold within 24 hours\n",
    "\n",
    "X_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the added column and save the dataframe\n",
    "\n",
    "X_test_final = X_test_final.drop(['predicted_label'], axis = 1)\n",
    "\n",
    "X_test_final.to_parquet('predictions.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
